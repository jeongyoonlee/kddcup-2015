\section{Classification Algorithms}
We selected algorithms that achieve good predictive performance, process large sparse data sets efficiently (with exception of K-Nearest Neighbors) and differ from other algorithms.  The 8 classification algorithms selected are as follows:
\begin{itemize}
%%\setlength\itemsep{0em}
\item Gradient Boosting Machine (GBM): We trained 26 GBM classifiers using the Scikit-Learn Python package \cite{scikit-learn} and XGBoost \cite{chen2015xgboost}.  We used various tree structures of 4 to 10 maximum depths and 0.004 to 0.05 shrinkage rates.
\item Neural Networks (NN): We trained 14 NN classifiers with the dropout \cite{srivastava2014dropout}, rectified linear unit (ReLU) \cite{dahl2013improving} transfer function and sigmoid activation function.  We used various network architectures of 1 to 3 hidden layers and 16 to 500 hidden units per layer.  We wrote our own C++ NN implementation optimized for sparse data sets.  
\item Factorization Machine (FM): We trained 12 FM classifiers using libFM \cite{rendle2012factorization} and libFFM \cite{libffm}.  We used 2-way interaction dimensions of 4 to 20.  We transformed count variables $x$ into $\log{(1 + x)}$.
\item Logistic Regression (LR): We trained 6 LR classifiers using the Scikit-Learn Python package \cite{scikit-learn} and Vowpal Wabbit \cite{langford2007vowpal}.  We used the regularization parameter $C=0.01$.  We transformed count variables $x$ into $\log{(1 + x)}$.
\item Kernel Ridge Regression (KRR): We trained 2 KRR classifiers using our own C++ implementation.  We used the ridge regression constant $\lambda=1.5e-3$ with the Gaussian kernel.  We transformed count variables $x$ into $\log{(1 + x)}$.
\item Extremely Randomized Trees (ET): We trained 2 ET classifiers using the Scikit-Learn Python package \cite{scikit-learn}.
\item Random Forests (RF): We trained 1 RF classifier using the Scikit-Learn Python package \cite{scikit-learn}.
\item K-Nearest Neighbors (KNN): We trained 1 KNN classifier using our own C++ implementation.  We used $k=124$ with the Euclidean distance.  We transformed count variables $x$ into $\log{(1 + x)}$.
\end{itemize}