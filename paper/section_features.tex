\section{Feature Engineering}
Our team members extracted 7 feature sets, namely F1, F2, F3, F4, F5, F6, and F7 from raw data independently.

\subsection{Data Sets}
Activity logs of 200,906 enrollments from 112,448 students across 39 courses are provided.
Each activity is described by 6 fields of the username, course ID, timestamp, source, event, and object. 
For each object, 3 additional fields of the category, children, and start date are provided.
The training set consists of 8,157,278 logs from 120,543 enrollments with the target variable indicating if a student dropped out.  
The test set consists of 5,387,848 logs from 80,363 enrollments.
The full description of the data sets is available in \cite{kddcup2015_data}. In general, this data can be organized in 3 dimensional space of object, time, and event as shown in Figure 1. Feature engineering tasks were carried out based on these views.

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.5 \textwidth]{cube}
	\label{fig:cube}
	\caption{Data cube.}
\end{figure}


\subsection{Common Features}
Attributes available from raw data
There are common features across 7 feature sets, F1 through F7 as follows:
\begin{itemize}
	\item Number of objects
	\item Number of events
	\item Aggregation features of features above
\end{itemize}

The common features can be generated using cube operations. Figure 2 shows an example how weekly and monthly count features are calculated. First, the data is cut along with the object dimension. In this case, we choose to generate feature for users. Next, we select an event "navigate" in the event space to generate a time series presenting "navigate" event over the time. Finally, the drill-down operation is used to generate monthly or weekly count features.

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.5 \textwidth]{slice_and_dice}
	\label{fig:slice}
	\caption{Data slice and dice.}
\end{figure}

\subsection{F1}

The feature set F1 is generated by Chen and Ozaki and includes features as follows:

\begin{itemize}
  \setlength\itemsep{0em}
  \item Enrollment-based features 
  \item Username-based features 
  \item Username-based features for each courses 
  \item Features based on 10 days after the end date of course 
  \item Features based on 1 day after the end date of a course 
  \item Day-level features 
\end{itemize}

Table A1 in Appendix shows the full list of features in F1.

\subsection{F2}
The feature set F2 is generated by Yan and Zhou and includes features as follows:
\begin{itemize}
  \setlength\itemsep{0em}
  \item Visit time(hour, day) set features (including time span and max absent days)
  \item Act(event, object) counting features (some uses missed content counts)
  \item Course drop rate
  \item Number of courses the user enrolled
  \item Minimum time interval between time points(first visit, last visit, course begin, course end, 10 days after course end) of current course and another enrolled course
  \item Active days between course end and 10 days after course end
  \item Active days between last visit and course end
  \item Number of courses ended after current course end
\end{itemize}

Table A2 in Appendix shows the full list of features in F2.

\subsection{F3}
The feature set F3 is generated by Nguyen, and are categorized into 3 groups of the count, aggregation, and date features.

\subsubsection{Count Features}
There are a few entities such as user, course, and object in the training dataset.  Combining these entities together, we have user activities or events.  The simplest way to generate features from these events is to count the number of times an entity engaging in the event. The motivation is that the more a user participate in course, the less likely she drop out the course. Table 1 shows the list of count features in F3. 

\begin{center}
	\begin{table}[ht]
		\begin{minipage}{0.5 \textwidth}
			{
				\caption{List of count features in F3.}
				\small
				\hfill{}
				\begin{tabular}{|l|l|l|}
					\hline
					\textbf{No.}	&\textbf{Description}\tabularnewline \hline
					1 			& The log count of each user \tabularnewline
					2 			& The log count of each course \tabularnewline
					3			& The log count of each event \tabularnewline
					4 			& The log count of each user per week \tabularnewline
					5 			& The log count of each user per two weeks \tabularnewline
					6 			& The log count of each user per weekday \tabularnewline
					7 			& The log count of each user per month\tabularnewline
					8 			& The log count of each course per week \tabularnewline
					9 			& The log count of each course per two weeks \tabularnewline
					10 			& The log count of each course per weekday\tabularnewline
					11 			& The log count of each course per month \tabularnewline
					12 			& The log count of each event per week \tabularnewline
					13 			& The log count of each event per two weeks \tabularnewline
					14 			& The log count of each event per weekday \tabularnewline
					15 			& The log count of each event per month \tabularnewline
					\hline
				\end{tabular}
			}
			\hfill{}
			\label{tb:tnfeature1}
		\end{minipage}
	\end{table}
\end{center}

\subsubsection{Aggregation Features}
Aggregation features are calculated based on count features. Usually, each course would have a fixed schedule for users to study. Therefore, students enrolled in the course must have consistent activity patterns.  Aggregation features would measure the stability of course engagement.  These features are minimum, mean, median, maximum, and standard deviation of count features on date basis such as weekly, monthly, etc.

\subsubsection{Date Features}
To capture how often users participate in a certain course, we generated date features. Date features can be time span among user activities as well as time span from last activity and last course date. 

\subsection{F4}
The feature set F4 is generated by Jahrer, and includes features as follows:

\begin{itemize}
  \setlength\itemsep{0em}
  \item User ID 
  \item Course ID
  \item User ID count 
  \item Enrollment ID count 
  \item Enrollment ID $\rightarrow$ Source ID count 
  \item Enrollment ID $\rightarrow$ Event ID 
  \item Enrollment ID $\rightarrow$ Object ID count 
  \item Enrollment ID $\rightarrow$ Timestamp count
  \item User ID: floor(log(timespan$^2$+1))
  \item User ID $\rightarrow$ log(timespan to obj start + 1) 
  \item Enrollment ID $\rightarrow$ timespan statistics 
\end{itemize}

\subsection{F5}
The feature set F5 is generated by Bay, and includes features as follows:
\begin{itemize}
  \setlength\itemsep{0em}
  \item Course ID - One-hot-encoded course\_id
  \item Source time counts  by enrollment - The log count of each source type per day for each enrollment
  \item Source time counts by course id - The log count of each source type per day for each course id
  \item Event time counts by enrollment - The log count of each event type per day for each enrollment
  \item Event time counts by course id - The log count of each event type per day for each course id

\end{itemize}

\subsection{F6}
The feature set F6 is generated by Lee, and includes features as follows:

\begin{itemize}
  \setlength\itemsep{0em}
  \item User ID - One-hot-encoded username. Usernames appearing less than 100 times in training log data are grouped together as one user ID. 
  \item Course ID - One-hot-encoded course\_id.
  \item Source Event - One-hot-encoded combination of source and event.
  \item Object ID - One-hot-encoded object.  Objects appearing less than 100 times in training log data are grouped together as one object ID.
  \item Count - Number of log entries for an hour\_id.
  \item Object Category - Number of log entries with an object category for an enrollment\_id.
  \item Number of Children Objects - One-hot-encoded total number of object's children for an enrollment\_id.
  \item Object Timespan - One-hot-encoded timespan in days between object's start date and last day of the class
  \item Day of Class - One-hot-encoded day of the class
  \item Week of Class - One-hot-encoded week of the class
  \item End Month of Class - One-hot-encoded end month of the class
  \item Object Started in Dropout Period - Binary variable that is 1 if object started after but before 10 days after last day of the class and 0 otherwise.
\end{itemize}

\subsection{F7}

The feature set F7 is generated by Ozaki, and encodes target variables for each days.  By adding F7 features, the best CV and public leaderboard score of our single model improved by 0.000846 and 0.001404 respectively. 

\begin{itemize}
  \setlength\itemsep{0em}
  \item For 10 days after the end date of each course, number of active enrollment\_id, which target variables are 1 in the training set, enrolled by an username.
  \item For 10 days after the end date of each course, number of active enrollment\_id, which target variables are 0 in the training set, enrolled by an username.
  \item For 10 days after the end date of each course, number of active enrollment\_id (in this case, days between last access and the end date of the course are also counted for active days), which target variables are 1 in the training set, enrolled by an username.
  \item For 10 days after the end date of each course, number of active enrollment\_id (in this case, days between last access and the end date of the course are also counted for active days), which target variables are 0 in the training set, enrolled by an username.
  \item For 14 days before the end date of each course, number of active enrollment\_id, which target variables are 1 in the training set, enrolled by an username.
  \item For 14 days before the end date of each course, number of active enrollment\_id, which target variables are 0 in the training set, enrolled by an username.
  \item For 14 days before the end date of each course, number of active enrollment\_id (in this case, days between last access and the end date of the course are also counted for active days), which target variables are 1 in the training set, enrolled by an username.
  \item For 14 days before the end date of each course, number of active enrollment\_id (in this case, days between last access and the end date of the course are also counted for active days), which target variables are 0 in the training set, enrolled by an username.
\end{itemize}

\subsection{Denoising Autoencoder Features}
We generate denoising autoencoder (DAE) \cite{hinton2006reducing} features from feature sets above and use those as additional features.  
We experiment with two autoencoder networks:
\begin{itemize}
  \setlength\itemsep{0em}
  \item \textbf{Deep Stack} \cite{vincent2010stacked}: It is an architecture with input-x-x-x-input, where $x=1,000$ for example.
The resulting feature dimensionality is $3 \times x$. We extract outputs from all layers as new features.
  \item \textbf{Bottleneck}  \cite{sainath2012auto} : It is an architecture with one layer with significantly fewer neurons such as input-1000-1000-30-1000-1000-input for example, which results in 30 features.
\end{itemize}
Both variants are trained with stochastic mini-batch SGD on the original training and test feature set.
We use the ReLU transfer function in hidden layers and the linear function in the output and bottleneck layers.
