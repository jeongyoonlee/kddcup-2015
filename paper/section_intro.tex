\section{Introduction}
The task of KDD Cup 2015 is to predict the likelihood of dropout for students on XuetangX, one of the largest Massive Open Online Course (MOOC) platforms in China.

Activity logs of 200,906 enrollments from 112,448 students across 39 courses are provided.
Each activity is described by 6 fields of the username, course ID, timestamp, source, event, and object. 
For each object, 3 additional fields of the category, children, and start date are provided.
The training set consists of 8,157,278 logs from 120,543 enrollments with the target variable indicating if a student dropped out.  
The test set consists of 5,387,848 logs from 80,363 enrollments.
The full description of the data sets is available in \cite{kddcup2015_data}



Our final solution is a joint work from 9 data scientists, distributed around the world.
The pipeline from raw data to final solution is as follows:
\begin{itemize}
  \setlength\itemsep{0em}
  \item Hand crafted feature engineering (most of hard work)
  \item Automatic feature design (autoencoder)
  \item Individual models (gbm, nn, factor model,..)
  \item Stage-I ensemble (blends individual models)
  \item Stage-II ensemble (blends stage-I ensemble models)
  \item Stage-III ensemble (blends stage-II ensemble models)
\end{itemize}

% I think our ensemble framework is different from Otto competition winner's:  Theirs is a stage-II and ours is a stage-III.
% This approach was published by a winning team of Otto kaggle competition \cite{otto},\cite{triskelion}.